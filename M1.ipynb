{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 0) 라이브러리 & 데이터 로드\n",
    "# ───────────────────────────────────────────────\n",
    "import numpy as np, pandas as pd, optuna, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "\n",
    "# (가상의) PropertyRecommender 인스턴스\n",
    "from my_reco import reco   # ← 기존 클래스 그대로 사용\n",
    "# ---------------------------\n",
    "LOG_F = Path(\"param_precision_log.csv\")\n",
    "MAX_K = 10\n",
    "PREC_MIN = 0.60          # Precision 제약\n",
    "TRIALS_FIRST = 50        # 1차 탐색 trial 수\n",
    "TRIALS_NEXT  = 20        # 매 주기 추가 trial 수\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 1) 내부 로지스틱 회귀 모델 학습  (분류-회귀)\n",
    "# ───────────────────────────────────────────────\n",
    "#   – 기존 prepare_logistic_dataset() 함수 사용\n",
    "#   – 임시 가중치 (1,1,1,  k=5, 1,1) 으로 후보 생성\n",
    "# ------------------------------------------------\n",
    "X_all, y_all = reco.prepare_logistic_dataset(\n",
    "    w_fin=[1,1,1], k=5, w_prop=[1,1], top_n=5)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, stratify=y_all, random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "clf    = LogisticRegression(solver='liblinear', max_iter=200).fit(\n",
    "            scaler.transform(X_tr), y_tr)\n",
    "\n",
    "print(\"▪ 내부 로지스틱 AUC:\",\n",
    "      roc_auc_score(y_te, clf.predict_proba(scaler.transform(X_te))[:,1]))\n",
    "# 모델을 pickle-like 파일로 저장 (재시동 대비)\n",
    "joblib.dump(clf,   \"logistic_model.joblib\")\n",
    "joblib.dump(scaler,\"scaler.joblib\")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 2) Precision 평가 함수  (내부 모델 사용)  ※ 핵심\n",
    "# ───────────────────────────────────────────────\n",
    "def precision_at_k(w_fin, k, w_prop, lam_k, company_ids):\n",
    "    \"\"\"\n",
    "    • 가중치·k 로 후보 생성  →  로지스틱 P(y=1|x) 예측\n",
    "    • 상위 k 매물 Precision@k  →  Penalty 적용 후 반환\n",
    "    \"\"\"\n",
    "    # ------ TODO: 실제 추천 로직 호출 ----------------\n",
    "    # precs = reco.batch_evaluate(\n",
    "    #           w_fin=w_fin, k=k, w_prop=w_prop, top_n=k,\n",
    "    #           company_ids=company_ids,\n",
    "    #           clf_fixed=clf, scaler=scaler)\n",
    "    # -------------------------------------------------\n",
    "    # ↓ 데모용 난수 (0.55~0.70)\n",
    "    rng = np.random.default_rng(hash(tuple(w_fin)+tuple(w_prop)+tuple([k])) & 0xffff)\n",
    "    precs = 0.55 + 0.15*rng.random()\n",
    "    # -------------------------------------------------\n",
    "    if precs < PREC_MIN:\n",
    "        return None               # 제약 위반\n",
    "    return precs - lam_k*(k/MAX_K)\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 3) Optuna objective         (하이퍼파라미터 탐색)\n",
    "# ───────────────────────────────────────────────\n",
    "def objective(trial):\n",
    "    w_fin  = np.array([trial.suggest_float('w1',0,5),\n",
    "                       trial.suggest_float('w2',0,5),\n",
    "                       trial.suggest_float('w3',0,5)])\n",
    "    k      = trial.suggest_int  ('k',1,MAX_K)\n",
    "    w_prop = np.array([trial.suggest_float('wa',0,5),\n",
    "                       trial.suggest_float('wp',0,5)])\n",
    "    lam    = trial.suggest_float('lam',0,1)\n",
    "    score  = precision_at_k(w_fin,k,w_prop,lam,trainval_ids)\n",
    "    if score is None:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    return score\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 4) 80:20 기업 분할 & 1차 탐색 실행\n",
    "# ───────────────────────────────────────────────\n",
    "all_companies = np.array(reco.df_fin.index)\n",
    "trainval_ids, test_ids = train_test_split(\n",
    "    all_companies, test_size=0.2, random_state=42)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=TRIALS_FIRST)\n",
    "\n",
    "print(\"◎ 1차 Best:\", study.best_value, study.best_params)\n",
    "\n",
    "# trial 결과 로그 → CSV (누적)\n",
    "df_trials = study.trials_dataframe()[['params_w1','params_w2','params_w3',\n",
    "                                      'params_k','params_wa','params_wp',\n",
    "                                      'params_lam','value']]\n",
    "df_trials.columns = ['w1','w2','w3','k','wa','wp','lam','precision']\n",
    "df_trials.to_csv(LOG_F, index=False)\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 5) 로그 기반 서로게이트 회귀  (GradientBoostingRegressor)\n",
    "# ───────────────────────────────────────────────\n",
    "def fit_surrogate():\n",
    "    log_df = pd.read_csv(LOG_F)\n",
    "    X = log_df.drop(columns=['precision']).values\n",
    "    y = log_df['precision'].values\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        GradientBoostingRegressor(n_estimators=300, random_state=0))\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "surrogate = fit_surrogate()\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 6) 서로게이트로 ‘유망 후보’ 200개 샘플 & 실제 평가\n",
    "# ───────────────────────────────────────────────\n",
    "rng  = np.random.default_rng(0)\n",
    "cand = rng.uniform(size=(200,7))\n",
    "cand[:,0:3] *= 5            # w_fin 0~5\n",
    "cand[:,3]   = (cand[:,3]*MAX_K).astype(int)+1\n",
    "cand[:,4:6] *= 5            # w_prop 0~5\n",
    "# lam 그대로 0~1\n",
    "preds = surrogate.predict(cand)\n",
    "best_i = preds.argmax()\n",
    "x_best = cand[best_i]\n",
    "\n",
    "true_score = precision_at_k(\n",
    "    w_fin=x_best[:3], k=int(x_best[3]),\n",
    "    w_prop=x_best[4:6], lam_k=x_best[6],\n",
    "    company_ids=trainval_ids)\n",
    "\n",
    "print(\\\"● Surrogate top-1 pred=%.4f  →  실제=%.4f\\\" % (preds[best_i], true_score))\n",
    "\n",
    "# 새 trial을 study.enqueue_trial 로 추가해도 되고,\n",
    "# 다음 루프에서 objective() 가 그대로 평가하도록 할 수도 있습니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
