{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776b19fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_KIC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geodesic\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m haversine_distances\n\u001b[0;32m----> 4\u001b[0m center_locations \u001b[38;5;241m=\u001b[39m \u001b[43mdf_KIC\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_lat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_lon\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_center_name\u001b[39m(name):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_KIC' is not defined"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "center_locations = df_KIC[['center_name', 'center_lat', 'center_lon']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "import re\n",
    "def normalize_center_name(name):\n",
    "    name = name.strip()\n",
    "    name = name.replace(' ', '').replace('\\u3000', '')\n",
    "    return name\n",
    "\n",
    "center_locations['center_name'] = center_locations['center_name'].apply(normalize_center_name)\n",
    "df_subway['center_name'] = df_subway['center_name'].apply(normalize_center_name)\n",
    "df_road['center_name'] = df_road['center_name'].apply(normalize_center_name)\n",
    "\n",
    "center_locations = center_locations.merge(df_road, on='center_name', how='left')\n",
    "center_locations = center_locations.rename(columns={'road_score': 'road_score_100'})\n",
    "\n",
    "def subway_score(distances, cutoff):\n",
    "    filtered = [d for d in distances if d <= cutoff]\n",
    "    if not filtered:\n",
    "        return 0\n",
    "    J_list = [(cutoff - d) / 20 for d in filtered]\n",
    "    k_list = [1 / d for d in filtered]\n",
    "    return sum(J * k for J, k in zip(J_list, k_list)) / sum(k_list)\n",
    "\n",
    "def convenience_score(distances, cutoff):\n",
    "    filtered = [d for d in distances if d <= cutoff]\n",
    "    if not filtered:\n",
    "        return 0\n",
    "    J_list = [(cutoff - d) / 50 for d in filtered]\n",
    "    k_list = [1 / d for d in filtered]\n",
    "    return sum(J * k for J, k in zip(J_list, k_list)) / sum(k_list)\n",
    "\n",
    "def bank_score(distances, cutoff):\n",
    "    return 20 if any(d <= cutoff for d in distances) else 0\n",
    "\n",
    "def calc_infra_scores(center_df, subway_df, max_neighbors=50, cutoff=2000):\n",
    "    results = []\n",
    "    for _, row in center_df.iterrows():\n",
    "        name = row['center_name']\n",
    "        lat, lon = row['center_lat'], row['center_lon']\n",
    "        center_coord_rad = np.radians([[lat, lon]])\n",
    "        convenience_coords_rad = np.radians(df_convenience[['위도', '경도']].dropna().values)\n",
    "        bank_coords_rad = np.radians(df_bank[['위도', '경도']].dropna().values)\n",
    "\n",
    "        s_dists = subway_df[subway_df['center_name'] == name]['distance'].tolist()\n",
    "        c_dists = haversine_distances(center_coord_rad, convenience_coords_rad)[0] * 6371000\n",
    "        b_dists = haversine_distances(center_coord_rad, bank_coords_rad)[0] * 6371000\n",
    "\n",
    "        \n",
    "        s_score = subway_score(s_dists, 1500)\n",
    "        #c_score = convenience_score(c_dists, 1500)\n",
    "        b_score = bank_score(b_dists, 1000)\n",
    "        r_score = row.get('road_score_100', 0) or 0\n",
    "        total_score = (s_score + b_score + r_score)\n",
    "\n",
    "        results.append({\n",
    "            'center_name': name,\n",
    "            'center_lat': lat,\n",
    "            'center_lon': lon,\n",
    "            'subway_score': s_score,\n",
    "            'bank_score': b_score,\n",
    "            'road_score': r_score,\n",
    "            'infra_score': total_score\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_infra_score = calc_infra_scores(center_locations, df_subway)\n",
    "df_infra_score = df_infra_score.groupby('center_name', as_index=False).mean()\n",
    "\n",
    "df_infra_score.to_csv(\"./infra_score.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
